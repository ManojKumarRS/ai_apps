LangChain orchestrates LLM tools and retrieval chains.
ChromaDB stores and retrieves dense vector embeddings efficiently.
Ollama runs local LLMs like Llama 3 for private inference.
